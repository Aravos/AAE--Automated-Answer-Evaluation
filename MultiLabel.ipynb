{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertModel, BertForSequenceClassification, get_linear_schedule_with_warmup\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
    "import os\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased',num_labels = 21,output_attentions = False,output_hidden_states = False)\n",
    "optimizer = torch.optim.AdamW(model.parameters(),lr = 2e-5, eps = 1e-8)\n",
    "current_directory = \"C:\\\\07-Project\\\\Final Project 8th Sem\\\\01-NLP\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_training = pd.read_csv(os.path.join(current_directory,\"Custom-Dataset.csv\"), encoding=\"utf-8\")\n",
    "data_training.head()\n",
    "questions = []\n",
    "target_answers = []\n",
    "answers = []\n",
    "labels = []\n",
    "max_len = 0\n",
    "\n",
    "for index,row in data_training.iterrows():\n",
    "    target_answers.append(row[\"reference_answer_en\"].translate(str.maketrans('', '', string.punctuation)).lower())\n",
    "    answers.append(row[\"student_answer_en\"].translate(str.maketrans('', '', string.punctuation)).lower())\n",
    "    labels.append(row[\"Average_Mark\"])\n",
    "\n",
    "for i in range(0,len(answers)):\n",
    "    input_ids = tokenizer.encode(answers[i],target_answers[i], add_special_tokens=True)\n",
    "    max_len = max(max_len, len(input_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_for_bert(answers,target_answers):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    token_type_ids = []\n",
    "    for i in range(0,len(answers)):\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "                        answers[i],\n",
    "                        target_answers[i],\n",
    "                        add_special_tokens = True,\n",
    "                        max_length = max_len,\n",
    "                        truncation = True,\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,\n",
    "                        return_tensors = 'pt',\n",
    "                   )\n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "        token_type_ids.append(encoded_dict['token_type_ids'])\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "    return input_ids,token_type_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids,token_type_ids, attention_masks = preprocessing_for_bert(answers,target_answers)\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "token_type_ids = torch.cat(token_type_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "index = data_training.index.tolist()\n",
    "tensor_index = torch.tensor(index)\n",
    "dataset = TensorDataset(input_ids, attention_masks,token_type_ids, labels,tensor_index)\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_data, val_data = random_split(dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_data,os.path.join(current_directory, \"dataset\", \"train_dataset.pt\"))\n",
    "torch.save(val_data,os.path.join(current_directory, \"dataset\", \"test_dataset.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.load(os.path.join(current_directory, \"dataset\", \"train_dataset.pt\"))\n",
    "val_data = torch.load(os.path.join(current_directory, \"dataset\", \"test_dataset.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dataloader = DataLoader(train_data,sampler = RandomSampler(train_data),batch_size = batch_size)\n",
    "validation_dataloader = DataLoader(val_data,sampler = SequentialSampler(val_data),batch_size = batch_size)\n",
    "epochs = 4\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0,num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = preds.flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return pearsonr(pred_flat,labels_flat)[0]\n",
    "def flat_rmse(preds, labels):\n",
    "    pred_flat = preds.flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return sqrt(mean_squared_error(pred_flat,labels_flat))\n",
    "def weights_init(m):\n",
    "  torch.nn.init.xavier_uniform(m.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global predictions, indexes, labels_test\n",
    "predictions = np.array([])\n",
    "indexes = np.array([])\n",
    "labels_test = np.array([])\n",
    "def get_predictions(p,l,i):\n",
    "  global predictions, indexes, labels_test\n",
    "  predictions = np.concatenate((predictions,p.flatten()),axis=0)\n",
    "  indexes = np.concatenate((indexes,i.flatten()),axis=0)\n",
    "  labels_test = np.concatenate((labels_test,l.flatten()), axis=0)\n",
    "def flat_accuracy_classification_task(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "training_stats = []\n",
    "total_t0 = time.time()\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "    t0 = time.time()\n",
    "    total_train_loss = 0\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        if step % 10 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('Batch:', step, \"Time:\", elapsed)\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_type_token_ids = batch[2].to(device)\n",
    "        b_labels = batch[3].to(device)\n",
    "        b_index = batch[4].to(device)\n",
    "        model.zero_grad()\n",
    "\n",
    "        rounded_labels = torch.round(b_labels)\n",
    "        mapped_labels = rounded_labels.clamp(min=0, max=5)\n",
    "        one_hot_labels = F.one_hot(mapped_labels.long(), num_classes=6).float()\n",
    "        outputs = model(b_input_ids, \n",
    "                        token_type_ids=b_type_token_ids, \n",
    "                        attention_mask=b_input_mask,\n",
    "                        labels=one_hot_labels)\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        total_grades = 0\n",
    "        l = [0,1,2,3,4,5]\n",
    "        for logits_batch in logits:\n",
    "            probabilities = F.softmax(logits_batch)\n",
    "            batch_grade = sum(probabilities[i] * l[i] for i in range(len(probabilities)))\n",
    "            print(batch_grade)\n",
    "            total_grades += batch_grade.item()\n",
    "\n",
    "        print(\"Total grades for the batch:\", total_grades)\n",
    "        \n",
    "        total_train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\\nAverage training loss:\", avg_train_loss)\n",
    "    print(\"Training epoch took:\", training_time)\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "    model.eval()\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    for batch in validation_dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_type_token_ids = batch[2].to(device)\n",
    "        b_labels = batch[3].to(device)\n",
    "        b_index = batch[4]\n",
    "        with torch.no_grad():\n",
    "            output = model(b_input_ids, token_type_ids=b_type_token_ids, attention_mask=b_input_mask, labels=b_labels)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        total_eval_loss += loss.item()\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        get_predictions(logits,label_ids,b_index.numpy())\n",
    "\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    print(\"  Validation Loss:\", round(avg_val_loss, 2))\n",
    "    \n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"Total Time:\", format_time(time.time()-total_t0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), os.path.join(current_directory, \"BERT_Model\",\"BERT_MultiModel.pth\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
